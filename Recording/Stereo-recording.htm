<html>

<head>
<meta http-equiv="Content-Language" content="en-us">
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<meta name="GENERATOR" content="Microsoft FrontPage 4.0">
<meta name="ProgId" content="FrontPage.Editor.Document">
<title>Recording what we hear</title>
<meta name="Microsoft Border" content="tlb, default">
</head>

<body stylesrc="../index.htm" background="../images/graphics/bg-sand4.gif"><!--msnavigation--><table border="0" cellpadding="0" cellspacing="0" width="100%"><tr><td>

<p align="left"><a href="../index.htm"><img border="0" src="../_borders/banner-1.gif" width="620" height="99"></a>
</p>

<div align="center">
  <center>
  <table border="0" cellspacing="1">
    <tr>
      <td width="100%">
        <p align="center"><font FACE="Arial" SIZE="2">&nbsp;<a href="../LXmini/Introduction.htm"><img border="0" src="../_borders/lxmini-3b.jpg" width="115" height="100"></a>&nbsp;
        <a href="../LXmini/Introduction.htm"><img border="0" src="../images/photos/LXmini-s.jpg" width="66" height="100"></a>&nbsp;
        <a href="../LXmini/Introduction.htm"><img border="0" src="../_borders/lxmini-1b.jpg" width="58" height="100"></a>&nbsp;
        <a href="../LXmini/LXmini+2.htm"><img border="0" src="../images/photos/LXmini2-2s.jpg" width="67" height="100"></a>&nbsp;
        <a href="../LXmini/LXstudio.htm"><img border="0" src="../images/photos/LXstudio-s.jpg" width="67" height="100"></a>
        &nbsp;<a href="../LX521/LX521_4.htm"><img border="0" src="../_borders/LX521-top100.jpg" width="85" height="100"></a>&nbsp;
        <a href="../LX521/LX521_4.htm"><img border="0" src="../images/photos/LX521-s.jpg" width="67" height="100"></a>&nbsp;
        <a href="../orion_challenge.htm"><img border="0" src="../_borders/orion-4f.jpg" width="56" height="100"></a>
        &nbsp;<a href="../orion_asp.htm"><img border="0" src="../images/photos/IMG_1065c100s.jpg" width="79" height="100"></a>
        &nbsp;<a href="../Pluto/electronics.htm"><img border="0" src="../_borders/module484-100.jpg" width="91" height="100"></a>&nbsp;
        <a href="../Pluto/Pluto-2.1.htm"><img border="0" src="../images/photos/Pluto-SPC-s2.jpg" width="67" height="100"></a>&nbsp;
        &nbsp;&nbsp;
        <a href="../Pluto/supplies.htm"><br>
        </a><span style="letter-spacing: 5pt">----- Experience in your own room
        the magical nature of stereo sound -----</span></font></p>
      </td>
    </tr>
  </table>
  </center>
</div>

</td></tr><!--msnavigation--></table><!--msnavigation--><table border="0" cellpadding="0" cellspacing="0" width="100%"><tr><td valign="top" width="1%">

<h4>&nbsp;</h4>

<table border="0" width="100%" cellspacing="4" bgcolor="#FFFFFF">
  <tr>
    <td width="100%" background="../images/graphics/bg-notepaper1.gif" align="center"><a href="../about_me.htm"><img border="0" src="../images/photos/sl3-100.jpg" width="100" height="145"></a></td>
  </tr>
</table>

<h4>&nbsp;</h4>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF"><a href="../What_is_new_at_linkwitzlab.htm"><b><font face="Arial" color="#008080" size="4">What's
      new</font></b></a></td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF">
      <p align="center"><b><a href="../Store/windows.htm" target="_blank"><font face="Arial" size="4" color="#008080">LX
      - Store</font></a></b></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF">
      <p align="center"><a href="../Fitz/considerations.htm" target="_blank"><b><font face="Arial" color="#008080" size="3">Conversations<br>
      with Fitz</font></b></a></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF">
      <p align="center"><a href="http://oplug-support.org/" target="_blank"><b><font face="Arial" color="#008080" size="3">OPLUG<br>
      Forum</font></b></a></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="0" width="100%" cellpadding="5" bgcolor="#FFFFFF" cellspacing="4">
  <tr>
    <td width="100%" bgcolor="#FFFFFF" background="../images/graphics/bg-notepaper1.gif">
<p><font face="Arial" color="#ff0000" size="4"><b>Basics</b></font></p>
<p><font face="Arial" size="2"><b><a href="../The_Magic/The_Magic.htm">The Magic
in 2-Channel Sound</a></b></font></p>
<p><a href="../frontiers.htm"><font face="Arial" size="2">Issues in speaker<br>
design</font></a></p>
<p><font face="Arial" size="2"><a href="../models.htm">Dipole
models</a></font></p>
<p><font face="Arial" size="2"> <a href="../filters.htm">Active
filters</a></font></p>
<p><font face="Arial" size="2"><a href="../Amplifiers-etc/Distortion.htm">Amplifiers
etc</a></font></p>
<p><font face="Arial" size="2"><a href="../sys_test.htm#Mic">Microphone</a></font></p>
<p><font face="Arial" size="2"><a href="../faq.htm">FAQ's</a></font></p>
<p><font face="Arial" size="2"><a href="../speakers.htm">Loudspeakers</a></font></p>
<p><font face="Arial" size="2"><a href="../crossovers.htm">Crossovers</a></font></p>
<p><font face="Arial" size="2"><a href="../rooms.htm">Room acoustics</a></font></p>
<p><font face="Arial" size="2"><a href="AS_creation.htm">Stereo
Recording and Rendering</a></font></p>
<p><font face="Arial" size="2"><a href="../Audio_production/sf_symphony.htm">Audio production</a></font></p>
<p><font face="Arial" size="2"><a href="../conclusions.htm">Conclusions</a></font></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="0" width="100%" cellpadding="5" bgcolor="#FFFFFF" cellspacing="4">
  <tr>
    <td width="100%" bgcolor="#FFFFFF" background="../images/graphics/bg-notepaper1.gif">
<p><font face="Arial" color="#ff0000" size="4"><b>Projects</b></font></p>
<p><b><font face="Arial" size="2"><a href="../Fitz/considerations.htm">Your
own desig</a></font></b></p>
<p><font face="Arial" size="2"><a href="../LXmini/Introduction.htm"><b>LXmini</b></a></font></p>
<p><font face="Arial" size="2"><b><a href="../LXmini/LXmini+2.htm">LXmini+2</a></b></font></p>
<p><font face="Arial" size="2"><b><a href="../LXmini/LXstudio.htm">LXstudio</a></b></font></p>
<p><font face="Arial" size="2"><b><a href="../LX521/LX521_4.htm">LX521.4</a></b></font></p>
<p><a href="../LX521/Description.htm"><font face="Arial" size="2">LX521<br>
reference</font></a></p>
<p><font face="Arial" size="2"><a href="../orion_challenge.htm">ORION<br>
challenge</a></font></p>
<p><font face="Arial" size="2"><a href="../orion-rev3.htm">ORION-3.4</a></font></p>
<p><font face="Arial" size="2"><a href="../Pluto/Pluto-2.1.htm">PLUTO-2.1</a></font></p>
<p><font face="Arial" size="2"><a href="../Watson/watson.htm">WATSON-SEL</a></font></p>
<p><font face="Arial" size="2"><a href="../Pluto/subwoofer.htm">PLUTO+<br>
subwoofer</a></font></p>
<p><font face="Arial" size="2"><a href="../thor-intro.htm">THOR<br>
subwoofer</a></font></p>
<p><font face="Arial" size="2"><a href="../builtown.htm">PHOENIX<br>
dipole speaker</a></font></p>
<p><font face="Arial" size="2"><a href="../Removed&#32;pages/x-sb80-3wy.htm">Three-Box active<br>
system (1978)</a></font></p>
<p><font face="Arial" size="2"><a href="../reference_earphones.htm">Reference<br>
earphones</a></font></p>
<p><font face="Arial" size="2"><a href="../surround_system.htm">Surround<br>
sound</a></font></p>
<p><font face="Arial" size="2"><a href="../Loudspeaker-Room/tests&amp;measurements.htm">Loudspeaker<br>
&amp; Room</a></font></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="0" width="100%" cellpadding="5" bgcolor="#FFFFFF" cellspacing="4">
  <tr>
    <td width="100%" bgcolor="#FFFFFF" background="../images/graphics/bg-notepaper1.gif"><font face="Arial" color="#ff0000" size="4"><b>Resources</b></font>
      <p>
<font face="Arial" size="2"><a href="../publications.htm">Publications</a></font>
      </p>
      <p><font face="Arial" size="2"><a href="../sound_picture_cd.htm">Sound
      recordings</a></font></p>
<p><font face="Arial" size="2"><a href="../links.htm">Links</a></font></p>
<p><font face="Arial" size="2"><a href="../Constant_directivity_louds.htm">Other
designs</a></font></p>
<p><font face="Arial" size="2"><a href="../my_setup.htm">My current setup</a></font></p>
<p><font face="Arial" size="2"><a href="../about_me.htm">About me</a></font></p>
<p><font face="Arial" size="2"><a href="../page_index.htm">Site map</a></font></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF">
      <p align="center"><a href="../index.htm"><b><font face="Arial" size="4" color="#008080">HOME</font></b></a></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>

<table border="0" width="100%" bgcolor="#FFFFFF" cellspacing="4" cellpadding="5">
  <tr>
    <td width="100%" background="../images/graphics/bg-notepaper1.gif"><font face="Arial"><b><font color="#FF0000" size="3" face="Arial"><i>------------------<br>
      </i></font><font color="#000000"><a href="../dpp/introduction.htm"><font size="3" face="Arial">Digital
      Photo<br>
      Processes</font></a></font></b></font>
    </td>
  </tr>
</table>

<p>&nbsp;</p>

<table border="0" width="100%" bgcolor="#FFFFFF" cellspacing="4" cellpadding="5">
  <tr>
    <td width="100%" background="../images/graphics/bg-notepaper1.gif"><font face="Arial"><b><font color="#FF0000">------------------</font><br>
      <a href="../Sea-Ranch/northern_california.htm">The<br>
      Sea Ranch</a></b></font>
    </td>
  </tr>
</table>

<p>&nbsp;</p>

<table border="0" width="100%" bgcolor="#FFFFFF" cellspacing="4" cellpadding="5">
  <tr>
    <td width="100%" background="../images/graphics/bg-notepaper1.gif"><font face="Arial"><b><font color="#FF0000">------------------</font><br>
      <a href="../Monika/MyDaughterTheJeweler.htm">My Daughter<br>
      the Jeweler</a></b></font>
    </td>
  </tr>
</table>

<h4>&nbsp;</h4>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF"><a href="../What_is_new_at_linkwitzlab.htm"><b><font face="Arial" color="#008080" size="4">What's
      new</font></b></a></td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF">
      <p align="center"><b><a href="../Store/windows.htm" target="_blank"><font face="Arial" size="4" color="#008080">LX
      - Store</font></a></b></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF">
      <p align="center"><a href="../Fitz/considerations.htm" target="_blank"><b><font face="Arial" color="#008080" size="3">Conversations<br>
      with Fitz</font></b></a></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF">
      <p align="center"><a href="http://oplug-support.org/" target="_blank"><b><font face="Arial" color="#008080" size="3">OPLUG<br>
      Forum</font></b></a></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>

<p>&nbsp;</p>

</td><td valign="top" width="24"></td><!--msnavigation--><td valign="top">

<p>&nbsp;</p>
<h1><font face="Arial" color="#FF0000"> Recording &amp; Rendering</font></h1>
<p><font face="Arial">--- <a href="AS_creation.htm">Recording
&amp; Rendering 101</a>  --- <a href="acoustics-hearing.htm">Acoustics vs.
Hearing</a>
--- <a
href="EBU_evaluation_CD.htm">Subjective evaluation</a> ---&nbsp;<br>
--- <a href="../stereo&#32;reproduction.htm">Room
optimized stereo</a> --- <a href="../reproduction.htm">Sound reproduction</a> ---
<b><font color="#000000">Recording
what we hear</font></b>  ---<br>
--- <a href="Stereo-recording-praxis.htm">Experimental results</a>
 --- <a href="record-play-map.htm">Theory</a>  --- <font color="#000000"> <a href="recording_angles.htm">SRA</a></font>
 ---&nbsp;<a href="../Sound_field/Field_control.htm">Sound field
control</a> ---&nbsp;</font></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h1><font face="Arial" color="#008080">Recording what we hear - A progression</font></h1>
<table border="0" width="100%" cellpadding="5">
  <tr>
    <td width="48%" valign="top"><img border="0" src="../images/graphics/A-forest2.jpg" width="400" height="285"></td>
    <td width="52%" valign="top"><font face="Arial">QUESTION:&nbsp;<br>
      If a tree falls in a dark forest and no one is there to hear it, does it
      make any sound?</font>
      <p><font face="Arial">ANSWER:&nbsp;<br>
      No!&nbsp;</font></p>
      <p><font face="Arial">The falling tree sets huge numbers of air particles
      into oscillatory motion. They push on other air particles and cause a
      chain reaction that propagates away from the tree at the speed of sound.
      In this process mechanical energy is transformed into heat as the wave
      hits other objects, is reflected, diffused and absorbed.&nbsp;</font></td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="0" width="100%" cellpadding="5">
  <tr>
    <td width="43%" valign="top"><font face="Arial"><img border="0" src="../images/graphics/B-binaural.jpg" width="350" height="332"></font></td>
    <td width="57%" valign="top"><font face="Arial">If a person is in range of
      the air particle disturbance, then a few particles hit the left and right
      ear drum. This is registered in the brain and perceived as sound.&nbsp;<br>
      For evolutionary reasons it is important to recognize the nature of a
      sound source. The detailed shape of the external ear, i.e. the pinna and
      the ear canal, changes the strength of the sound wave at the ear drum
      depending upon the frequency of oscillation and the direction from
      which the air particles arrive. This is further enhanced by the sound
      shadowing of the head between the ears. The separation of the two ears
      causes a delay between the particles arriving at each ear drum when the
      source is not located in the median plane, the vertical plane that bisects
      the body. Thus, turning the head sideways or up and down changes the air
      particle strength at the ear drums.&nbsp;<br>
      The brain has evolved to process spectral, temporal and directional cues
      to form a mental picture of the origin of a sound, its direction,
      distance, size and nature. This is further enhanced by visual and tactile
      cues, and certainly by learning and memory. </font></td>
  </tr>
</table>
<p><font face="Arial">If a person or brain B1 observes and perceives a tree
falling in the forest (B) and this sensation is to be transmitted to a second
person B2 in a different location and at a different time, then several pieces
of information have to be recorded. They would include the ear drum signals of
B1 and the body motion V in response to the sound wave and any structure borne
vibration. The ear drum signals would have to be applied to the ear drums of B2,
and the motional signals from B1 would have to impart the same motion to B2.
There are inherent errors in this transmission. For example, the outer ear of B1
does not match the outer ear of B2, but the brain of B2 is only experienced to process
sounds with its own ears. Also the details in neural wiring of brain B2 are
likely to be sufficiently different from B1 so that an exact duplication of
perception is ultimately not possible.</font></p>
<p><font face="Arial">Regardless of the seeming futility we try the next best
approach which is binaural recording and playback. Here the person B1 is
replaced by a dummy head with torso D. Microphones replace the ear drums. The
outer ears and the shape of the head are an average of human forms as are the
surface textures. The recorded dummy head signals should be applied to the ear
drums of a listener B3. This is not without problems.</font></p>
<table border="0" width="100%" cellpadding="5">
  <tr>
    <td width="48%" valign="top"><font face="Arial"><img border="0" src="../images/graphics/D-earphones.jpg" width="400" height="177"></font></td>
    <td width="52%" valign="top"><font face="Arial">Ear canal phones (D) have
      wearer specific frequency response errors, can become physically
      uncomfortable and may isolate the person too much from the
      surroundings.&nbsp;<br>
      Circum-aural headphones (E) tend to have ear cup resonances. They are
      lessened with supra-aural headphones, but those may suffer from
      insufficient isolation from ambient sounds.<br>
      In all three cases there are individual outer ear dependent frequency
      response aberrations and for optimum performance they need to be <a href="../reference_earphones.htm">individually
      equalized</a>.</font></td>
  </tr>
</table>
<p><font face="Arial">Binaural sound reproduction can be tonally and spatially
very realistic except for localization in the frontal hemisphere. There it
suffers from in-head localization. The soundstage is usually not perceived as
being outside and in front of the head. I have been told that out-of-head
localization can be learned, but have not spent enough time to find out if that
also works for me. The in-head soundstage follows any head movement rather than
being stationary. This provides a completely unnatural cue to the brain. It can
be avoided by tracking the movement of the head and adjusting each ear signal
according to the head's position relative to the soundstage. Video game consoles
sometimes use this technique and in combination with a visual image they can
give a realistic spatial rendering.</font></p>
<p><font face="Arial">So the simplified transmission system (C) above can reproduce a certain number of cues sufficiently close to create a fairly good
illusion of a real event, but lacks in frontal localization and in body related
tactile inputs compared to (B). If the dummy head recording is played back over
loudspeakers in a reflection free room (G), then two new problems become
apparent. The frequency spectrum of the recording had been modified by the
external ear of the dummy head D and is modified again by the external ear of
the listener B3. This causes a sound coloration that can be avoided by applying
the inverse of the head-related-transfer-function for a given loudspeaker and
listener setup to the microphone signals of D. In addition the signal
from the left loudspeaker impinges upon the left ear and the right ear.
Similarly the right speaker sends signals to both right and left ears. This
cross-talk between the ears can be cancelled for a precisely fixed loudspeaker
and listener setup. Compensating signals are added electronically to left and
right loudspeaker signals so that L<sub>L</sub> cancels at the left ear the
contribution from R<sub>L</sub>. Correspondingly R<sub>R</sub> compensates for L<sub>R</sub>.
Alternatively a wall can be placed between the speakers that extends forward to
the head of B3. It physically blocks the crosstalk signals L<sub>R</sub> and R<sub>L</sub>.
Both solutions confine the listener's head to a small region for the cancellation
to be effective and they do work well under anechoic playback conditions. The
required setup conditions are hardly met in typical living rooms (H) where a
multiplicity of loudspeaker sound reflections easily destroys the acoustic
balancing act. While the brain tries to compensates, it becomes eventually
tiring to listen.</font></p>
<table border="0" width="100%" cellpadding="5">
  <tr>
    <td width="54%" valign="top"><font face="Arial"><img border="0" src="../images/graphics/G-rooms.jpg" width="450" height="372"></font></td>
    <td width="46%" valign="top"><font face="Arial">The
      dummy head is sometimes replaced by a <a href="../sound_picture_cd.htm">sphere
      microphone</a>. It is an 8&quot; rigid sphere with omni-directional
      microphone capsules at the location of the ears, but with no pinna or ear
      canal.&nbsp;</font>
      <p><font face="Arial">Sphere recordings, though, are not the complete
      answer for commercially viable recordings. They tend to pick up too much
      of the reverberant sound field even when placed close to the performers.
      They depend upon adequate acoustics of the recording venue since they
      capture a spatial impression quite realistically.&nbsp;</font></p>
      <p><font face="Arial">Basically, though, accurate or realistic recordings
      have not been possible because of the absence of an accurate playback
      standard that could confirm such an achievement.&nbsp; With&nbsp;only
      loudspeakers of greatly variable performance&nbsp;to choose from - and
      interacting unpredictably&nbsp;in their unavoidably unique acoustic
      surroundings - recording practices substituted exaggerated clarity as a
      suitable - and achievable goal.&nbsp;&nbsp;</font></td>
  </tr>
</table>
<p><font face="Arial">That&nbsp;emphasis has continued to prejudice and
influence recording techniques to this day. Therefore it is common practice to
use a multitude of microphones to highlight individual performers or instrument
groups. Recordings are done in studios for full control over the reverberant
sound. Lost in the process is any sense of a coherent acoustic space, of the
venue acoustics, in the recording. Instead, the space in which the sound occurs
is often chopped up into isolated lumps.</font></p>
<p><font face="Arial">Typical loudspeakers in typical room setups are not
capable of reproducing a full spatial impression even if the cues for it are
imbedded in the recording. This is due to the <a href="../stereo&#32;reproduction.htm">room
reflections</a> which in turn are a function of the polar response of the
loudspeakers and their placement in the room. Thus what has been done to the
spatial aspect in the recording process goes largely unnoticed during playback.
Even the recording/mixing/mastering engineer was probably not aware of the
consequences of his decisions because the typical monitor loudspeakers are not
up to the task of telling him. Loudspeakers must be either full range
omni-directional or dipolar, and be placed away from reflecting surfaces, and be
placed symmetrical to the room boundaries. In that configuration the brain can
disassociate the room reflected sound from the loudspeaker direct sound and
fully use the spatial cues in the direct sound to form spatial impressions and
localization of phantom sources.</font></p>
<table border="0" width="100%" cellpadding="5">
  <tr>
    <td width="37%" valign="top"><font face="Arial"><img border="0" src="../images/graphics/I-concert.jpg" width="300" height="380"></font></td>
    <td width="63%" valign="top"><font face="Arial">It has been observed that
      quite realistic recordings can be made by simply placing small
      omni-directional <a href="../images/photos/stereo-mic2.JPG">microphone</a>
      capsules on the frame of eye glasses just in front of the pinna.
      Recordings in a concert hall (I) with live audience exhibit clarity and
      spatial realism, even when the seat is far from the orchestra. But they
      sound distant because the reverberant sound so dominates and due to the
      extraneous noises from nearby audience members. But if anything this adds
      to the naturalness. I have been impressed how the live direct sound from
      the orchestra seems to dominate the perception and the hall sound is
      merely heard as providing envelopment even when my seat is in row Y and
      far from the stage. It appears that a large amount of decorrelation of
      reverberant sound from direct sound is taking place in the brain. This
      seems to be similar to what can happen in a living room with proper
      loudspeakers and setup.&nbsp;</font>
      <p><font face="Arial">The microphones on the head are obviously similar to
      a sphere microphone. They have the same advantages and drawbacks. They do
      not replicate exactly what is perceived in the brain of a listener at that
      location. They do give a realistic spatial impression but lack the
      perceived intimacy of the live event.</font></p>
      <p><font face="Arial">It seems that two microphones cannot record at the
      same time a spatial impression and intimacy in the right proportions. Thus
      the idea of separating these two tasks emerged and that it should be
      possible to accomplish a coherent recording with four microphones.</font></td>
  </tr>
</table>
<p><font face="Arial">The microphone setup (K) consists of two main microphones
L<sub>M</sub> and R<sub>M</sub> and two ambient microphones L<sub>A</sub> and R<sub>A</sub>.
The main microphones are super-cardioids (Schoeps MK 41) for well controlled
off-axis frequency response. They are separated by D<sub>1</sub> to duplicate
the acoustic path length between the ears. They are angled to cover the width of
the sound source while being placed further from it than is usual. The overall
aim is to record an audience perspective of the source. The ambient microphones
are omni-directional (Schoeps MK 2S). They are placed sufficiently behind the
main microphones, D<sub>2</sub>, and apart from each other, D<sub>3</sub>, to be
decorrelated from each other. Typical dimensions could be D<sub>1</sub> = 8
inch, </font><font face="Symbol">a</font><font face="Arial"> = 110 degrees, D<sub>2</sub>
= 30 feet, D<sub>3</sub> = 40 feet.</font></p>
<table border="0" width="100%" cellpadding="4">
  <tr>
    <td width="66%" valign="top"><font face="Arial"><img border="0" src="../images/graphics/K-microphones.jpg" width="550" height="322"></font></td>
    <td width="34%" valign="top"><font face="Arial">The main and ambient
      microphone outputs are summed in each channel (L). The ambient output
      level is adjusted to provide a realistic balance when played back over
      ORION++ loudspeakers.</font>
      <p><font face="Arial">The 4-microphone configuration is being tested at
      this time by Don Barringer.&nbsp; Initial recordings of organ and chorus
      in Washington National Cathedral gave convincing evidence of the
      correctness of the configuration. The main microphones were 80 feet from
      the organ.</font></p>
      <p>&nbsp;</td>
  </tr>
</table>
<h3 align="left">&nbsp;</h3>
<h3 align="left"><b><font face="Arial" color="#008080">Recording and Environment</font></b></h3>
<p align="left"><font face="Arial">All acoustical events take place in an
environment. Those environments can be very different, like the relatively open
space of the falling tree, the large and closed space of a concert hall, a
restaurant or your bath room. We perceive the specifics of the environments from
the multitude of reflections of air particles that occur when they strike
boundaries in their path of propagation. Reflections are always delayed relative
to the time that air particle motion takes to propagate directly from source to receiver.
Thus any acoustic event that is perceived as sound has at least two elements to
it: the direct signal and the reflections from the environment. Our brain is
totally used to process that mix of information and we may become aware of the
two elements by paying attention.&nbsp;</font></p>
<p align="left"><font face="Arial">The 4-microphone setup captures the direct
and reflected signal spectra with temporal separation by placing the microphones
into different parts of the acoustic space. Thus, when played back over two
loudspeakers, stronger cues are presented to the brain about the acoustic source
and its environment than a two microphone setup could provide, which captures
both elements simultaneously and in difficult to control proportions. The ratio
of direct to ambient reflected signals is very different for a musician in the
orchestra, the conductor in front of the orchestra or a member of the audience
behind the conductor in the concert hall. Underlying any recording is a decision
as to which perspective to present to the loudspeaker listener. Is it the
musician's perspective, the conductor's, the audience's or none of the above and
instead some artificial perspective that serves a particular purpose? The
4-microphone setup appears to be well suited to capture the audience perspective
and might be called the &quot;D+R Stereo&quot; technique for capturing direct
and reflected sounds separately.</font></p>
<p align="left">&nbsp;</p>
<h3 align="left"><b><font face="Arial" color="#008080">Sound <a name="stream"> stream</a> segregation</font></b></h3>
<p align="left"><font face="Arial">In natural hearing the evolutionary and
adaptive processor between the ears is capable of segregating a direct sound
stream from a reflected sound stream and from a structure borne vibration. We
are able to perceive the direction from which sound is coming, the distance of
the source and even its size primarily from the direct sound. The reflected
sound can enhance or detract from this information and we can perceptually
remove it, if it is not relevant to the source information. This works in a wide
range of acoustic environments.&nbsp;</font></p>
<p align="left"><font face="Arial">For example, think of having a conversation
with another person at a cocktail party. At the same time there are many
conversations going on around you. This can make it difficult to understand your
partner. The sound stream that is coming from her to your left and right ears
tends to fuse with the many sound streams that are happening around you and are
also impinging on your ears. You may step closer to her to increase the volume
of this sound stream relative to the other streams which then become to you the
noisy background for your conversation. On the other hand you may be also
interested in the conversation between X and Y over in the corner of the room.
As you focus in your mind on that conversation you pick up segments of that
specific sound stream and make sense of them, and all this while you are having
a conversation here. Your brain is multi-tasking.</font></p>
<p align="left"><font face="Arial">I can say from personal experience that this
is a difficult process if you are not intimately familiar with the language that
is spoken around you. My native language is German and it took me years of
exposure to English to be able to process sound in the acquired language as
easily as in my native language. Certainly, language cognition is one element of
the &quot;cocktail party effect&quot;. Other elements are the timing differences
between left and right ear signals due to the direction from which a sound
stream arrives, the envelope modulation depth of the X-Y sound stream relative
to the background sound streams or noise, and the timing of the X-Y stream
segments relative to your conversation. It is difficult to hear while you are
talking.</font></p>
<p align="left"><font face="Arial">The venue in which the cocktail party takes
place also has an effect on the ease of conversation. If it is a large hall with
highly reflective surfaces and long reverberation time, then distant
conversations lose envelope modulation depth and are difficult to understand
even though the volume level in the hall may not be that high. The long
reverberation fuses distant streams. If the room is small and there are many
people, then the modulation depth of a more distant sound stream becomes low
even when its volume is high and thus fewer segments are heard and
recognized.&nbsp;&nbsp;</font></p>
<p align="left"><font face="Arial">When a recording is made, the microphones
capture the direct sound stream from the sound sources and the reflected sound
stream from the recording venue.&nbsp;</font></p>
<p align="left"><font face="Arial">When the recording is played back in
a room, then the listener is exposed again to two sound streams, the direct
sound from the two loudspeakers and the room reflected sound. Given that the
loudspeakers have uniform directivity, we apparently can perceptually segregate
the two streams to a large degree.&nbsp;This was recognized in the <a href="../stereo&#32;reproduction.htm">ORION
and PLUTO comparison</a>. </font></p>
<p align="left"><font face="Arial">Imbedded in the direct sound from the two
loudspeakers is the direct sound stream that the microphones received and
the recording venue's reflected stream. Thus during playback the processor
between the ears is asked to deal with four streams of acoustic information: the
direct loudspeaker sound and its reflection in the listening room, and the
direct microphone signal and its reflection in the recording venue.&nbsp;</font></p>
<p align="left"><font face="Arial">The proposed four microphone technique
captures direct and reflected sound streams in the recording venue with time and
intensity separation between them. Mixing the two streams in optimal proportion
before playback should give the listener's brain stronger cues for constructing
an illusion about the original sound sources in their acoustic space, similar to
what a person in the audience in that space would hear live. But, just as
language familiarity is helpful in the cocktail party effect, so is familiarity
with live acoustic events to recognize and appreciate spatial characteristics in
a recording. Most recording techniques aim for clarity first. Spatiality is
secondary and often synthesized which is readily recognized over ORION or
PLUTO.&nbsp;</font></p>
<p align="left"><font face="Arial">With four microphones both clarity and
spatiality should be captured. This is not an attempt at surround sound. The
sound stage in the listening room will always be behind the loudspeakers and in
that sense it is a spatial distortion relative to the recording situation. It is
an easily accepted distortion because of familiar elements in it.<br>
</font></p>
<p align="left"><font face="Arial">Related reading material:</font></p>
<ol>
  <li><font face="Arial">Francis Rumsey, &quot;Spatial Audio&quot;, Focal Press,
    2001.&nbsp;<br>
    Principles and practical considerations of spatial sound recording and
    reproduction. Particular emphasis is given to multichannel surround sound
    and 3D audio, including binaural approaches, without ignoring conventional
    stereo.<br>
    </font></li>
  <li><font face="Arial">Daniel J. Levitin, &quot;This Is Your Brain on Music -
    The Science of a Human Obsession&quot;, Dutton, 2006<br>
    </font></li>
  <li><font face="Arial">Barry Blesser &amp; Linda-Ruth Salter, &quot;Spaces
    speak, are you listening?&quot;, MIT Press, 2007<br>
    </font></li>
  <li><font face="Arial">Albert S. Bregman, &quot;Auditory Scene Analysis&quot;,
    MIT Press, 1999<br>
    </font></li>
  <li><font face="Arial"><a href="../accurate&#32;stereo&#32;performance.htm">Accurate
    Stereo</a> performance tests, December 2009</font></li>
</ol>
<p align="center">&nbsp;</p>
<table border="3" width="100%" cellpadding="10" bordercolorlight="#FFFFFF">
  <tr>
    <td width="68%" background="../images/graphics/bg-notepaper1.gif">
<p><font face="Arial"><i><a name="Don">The above discussion</a> of recording techniques has been
heavily influenced by numerous recent conversations with Don Barringer, a
retired recording engineer and musician.&nbsp;Don had build many of my earlier
loudspeaker designs in his search for sonically trustworthy recording
monitors.&nbsp;</i></font></p>
<p><font face="Arial"><i>My interest in recording began with Lyman Miller, a former
colleague from HP and early proponent and practitioner of sphere recordings and
with Russ Riley who used small microphone capsules looped over his ears to
record local symphony performances. Playback was over supra-aural headphones
that we each had equalized for our own ears.</i></font></p>
    </td>
    <td width="32%" background="../images/graphics/bg-notepaper1.gif" valign="top" align="center"><img border="0" src="../images/photos/don-bgr3.jpg" width="180" height="182"><br>
      <font face="Arial" size="1">Don Barringer, October 2004</font></td>
  </tr>
</table>
<p>&nbsp;</p>
<p align="center"><font face="Arial">-----------------------------------------------------------------------</font></p>
<p>&nbsp;</p>
&nbsp;<!--msnavigation--></td></tr><!--msnavigation--></table><!--msnavigation--><table border="0" cellpadding="0" cellspacing="0" width="100%"><tr><td>

<p>&nbsp;</p>
<table border="0" width="90%" cellpadding="10">
  <tr>
    <td width="10%" align="center"><a href="../IJAETv2n2a2-Linkwitz-1.pdf" target="_blank"><img border="0" src="../images/photos/SL-2013.jpg" width="150" height="200"></a></td>
    <td width="50%">
      <b><span style="letter-spacing: 1pt"><font color="#808080" face="Arial" size="5">What you hear is not the air pressure
      variation in itself&nbsp;<br>
      but what has drawn your attention<br>
 in the streams of superimposed air
      pressure variations&nbsp;<br>
 at your eardrums</font></span></b>
      <p><b><font
      face="Arial" size="4" color="#008080"><span style="letter-spacing: 1pt">An
      acoustic event has dimensions of Time, Tone, Loudness and Space<br>
      Have they been recorded and rendered sensibly?</span></font></b></p>
    </td>
  </tr>
  <tr>
    <td width="10%" colspan="2" align="center">
      <p><b><font face="Arial" color="#ff0000" size="5">___________________________________________________________<br>
      </font></b><font face="Arial" color="#000000" size="1">Last revised: 08/02/2018
      &nbsp; -&nbsp; © 1999-2017 LINKWITZ LAB, All Rights Reserved</font>
      <p>&nbsp;</td>
  </tr>
</table>

</td></tr><!--msnavigation--></table><!-- WiredMinds eMetrics tracking with Enterprise Edition V5.4 START -->
<script type='text/javascript' src='https://count.carrierzone.com/app/count_server/count.js'></script>
<script type='text/javascript'><!--
wm_custnum='98f60a12c56b8f6c';
wm_page_name='Stereo-recording.htm';
wm_group_name='/services/webpages/l/i/linkwitzlab.com/public/Recording';
wm_campaign_key='campaign_id';
wm_track_alt='';
wiredminds.count();
// -->
</script>
<!-- WiredMinds eMetrics tracking with Enterprise Edition V5.4 END -->
</body>

</html>
