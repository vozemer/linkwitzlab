<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<meta name="GENERATOR" content="Microsoft FrontPage 4.0">
<meta name="ProgId" content="FrontPage.Editor.Document">
<title>AS_creation</title>
<meta name="Microsoft Border" content="tlb, default">
</head>

<body stylesrc="../index.htm" background="../images/graphics/bg-sand4.gif"><!--msnavigation--><table border="0" cellpadding="0" cellspacing="0" width="100%"><tr><td>

<p align="left"><a href="../index.htm"><img border="0" src="../_borders/banner-1.gif" width="620" height="99"></a>
</p>

<div align="center">
  <center>
  <table border="0" cellspacing="1">
    <tr>
      <td width="100%">
        <p align="center"><font FACE="Arial" SIZE="2">&nbsp;<a href="../LXmini/Introduction.htm"><img border="0" src="../_borders/lxmini-3b.jpg" width="115" height="100"></a>&nbsp;
        <a href="../LXmini/Introduction.htm"><img border="0" src="../images/photos/LXmini-s.jpg" width="66" height="100"></a>&nbsp;
        <a href="../LXmini/Introduction.htm"><img border="0" src="../_borders/lxmini-1b.jpg" width="58" height="100"></a>&nbsp;
        <a href="../LXmini/LXmini+2.htm"><img border="0" src="../images/photos/LXmini2-2s.jpg" width="67" height="100"></a>&nbsp;
        <a href="../LXmini/LXstudio.htm"><img border="0" src="../images/photos/LXstudio-s.jpg" width="67" height="100"></a>
        &nbsp;<a href="../LX521/LX521_4.htm"><img border="0" src="../_borders/LX521-top100.jpg" width="85" height="100"></a>&nbsp;
        <a href="../LX521/LX521_4.htm"><img border="0" src="../images/photos/LX521-s.jpg" width="67" height="100"></a>&nbsp;
        <a href="../orion_challenge.htm"><img border="0" src="../_borders/orion-4f.jpg" width="56" height="100"></a>
        &nbsp;<a href="../orion_asp.htm"><img border="0" src="../images/photos/IMG_1065c100s.jpg" width="79" height="100"></a>
        &nbsp;<a href="../Pluto/electronics.htm"><img border="0" src="../_borders/module484-100.jpg" width="91" height="100"></a>&nbsp;
        <a href="../Pluto/Pluto-2.1.htm"><img border="0" src="../images/photos/Pluto-SPC-s2.jpg" width="67" height="100"></a>&nbsp;
        &nbsp;&nbsp;
        <a href="../Pluto/supplies.htm"><br>
        </a><span style="letter-spacing: 5pt">----- Experience in your own room
        the magical nature of stereo sound -----</span></font></p>
      </td>
    </tr>
  </table>
  </center>
</div>

</td></tr><!--msnavigation--></table><!--msnavigation--><table border="0" cellpadding="0" cellspacing="0" width="100%"><tr><td valign="top" width="1%">

<h4>&nbsp;</h4>

<table border="0" width="100%" cellspacing="4" bgcolor="#FFFFFF">
  <tr>
    <td width="100%" background="../images/graphics/bg-notepaper1.gif" align="center"><a href="../about_me.htm"><img border="0" src="../images/photos/sl3-100.jpg" width="100" height="145"></a></td>
  </tr>
</table>

<h4>&nbsp;</h4>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF"><a href="../What_is_new_at_linkwitzlab.htm"><b><font face="Arial" color="#008080" size="4">What's
      new</font></b></a></td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF">
      <p align="center"><b><a href="../Store/windows.htm" target="_blank"><font face="Arial" size="4" color="#008080">LX
      - Store</font></a></b></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF">
      <p align="center"><a href="../Fitz/considerations.htm" target="_blank"><b><font face="Arial" color="#008080" size="3">Conversations<br>
      with Fitz</font></b></a></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF">
      <p align="center"><a href="http://oplug-support.org/" target="_blank"><b><font face="Arial" color="#008080" size="3">OPLUG<br>
      Forum</font></b></a></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="0" width="100%" cellpadding="5" bgcolor="#FFFFFF" cellspacing="4">
  <tr>
    <td width="100%" bgcolor="#FFFFFF" background="../images/graphics/bg-notepaper1.gif">
<p><font face="Arial" color="#ff0000" size="4"><b>Basics</b></font></p>
<p><font face="Arial" size="2"><b><a href="../The_Magic/The_Magic.htm">The Magic
in 2-Channel Sound</a></b></font></p>
<p><a href="../frontiers.htm"><font face="Arial" size="2">Issues in speaker<br>
design</font></a></p>
<p><font face="Arial" size="2"><a href="../models.htm">Dipole
models</a></font></p>
<p><font face="Arial" size="2"> <a href="../filters.htm">Active
filters</a></font></p>
<p><font face="Arial" size="2"><a href="../Amplifiers-etc/Distortion.htm">Amplifiers
etc</a></font></p>
<p><font face="Arial" size="2"><a href="../sys_test.htm#Mic">Microphone</a></font></p>
<p><font face="Arial" size="2"><a href="../faq.htm">FAQ's</a></font></p>
<p><font face="Arial" size="2"><a href="../speakers.htm">Loudspeakers</a></font></p>
<p><font face="Arial" size="2"><a href="../crossovers.htm">Crossovers</a></font></p>
<p><font face="Arial" size="2"><a href="../rooms.htm">Room acoustics</a></font></p>
<p><font face="Arial" size="2"><a href="AS_creation.htm">Stereo
Recording and Rendering</a></font></p>
<p><font face="Arial" size="2"><a href="../Audio_production/sf_symphony.htm">Audio production</a></font></p>
<p><font face="Arial" size="2"><a href="../conclusions.htm">Conclusions</a></font></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="0" width="100%" cellpadding="5" bgcolor="#FFFFFF" cellspacing="4">
  <tr>
    <td width="100%" bgcolor="#FFFFFF" background="../images/graphics/bg-notepaper1.gif">
<p><font face="Arial" color="#ff0000" size="4"><b>Projects</b></font></p>
<p><b><font face="Arial" size="2"><a href="../Fitz/considerations.htm">Your
own desig</a></font></b></p>
<p><font face="Arial" size="2"><a href="../LXmini/Introduction.htm"><b>LXmini</b></a></font></p>
<p><font face="Arial" size="2"><b><a href="../LXmini/LXmini+2.htm">LXmini+2</a></b></font></p>
<p><font face="Arial" size="2"><b><a href="../LXmini/LXstudio.htm">LXstudio</a></b></font></p>
<p><font face="Arial" size="2"><b><a href="../LX521/LX521_4.htm">LX521.4</a></b></font></p>
<p><a href="../LX521/Description.htm"><font face="Arial" size="2">LX521<br>
reference</font></a></p>
<p><font face="Arial" size="2"><a href="../orion_challenge.htm">ORION<br>
challenge</a></font></p>
<p><font face="Arial" size="2"><a href="../orion-rev3.htm">ORION-3.4</a></font></p>
<p><font face="Arial" size="2"><a href="../Pluto/Pluto-2.1.htm">PLUTO-2.1</a></font></p>
<p><font face="Arial" size="2"><a href="../Watson/watson.htm">WATSON-SEL</a></font></p>
<p><font face="Arial" size="2"><a href="../Pluto/subwoofer.htm">PLUTO+<br>
subwoofer</a></font></p>
<p><font face="Arial" size="2"><a href="../thor-intro.htm">THOR<br>
subwoofer</a></font></p>
<p><font face="Arial" size="2"><a href="../builtown.htm">PHOENIX<br>
dipole speaker</a></font></p>
<p><font face="Arial" size="2"><a href="../Removed&#32;pages/x-sb80-3wy.htm">Three-Box active<br>
system (1978)</a></font></p>
<p><font face="Arial" size="2"><a href="../reference_earphones.htm">Reference<br>
earphones</a></font></p>
<p><font face="Arial" size="2"><a href="../surround_system.htm">Surround<br>
sound</a></font></p>
<p><font face="Arial" size="2"><a href="../Loudspeaker-Room/tests&amp;measurements.htm">Loudspeaker<br>
&amp; Room</a></font></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="0" width="100%" cellpadding="5" bgcolor="#FFFFFF" cellspacing="4">
  <tr>
    <td width="100%" bgcolor="#FFFFFF" background="../images/graphics/bg-notepaper1.gif"><font face="Arial" color="#ff0000" size="4"><b>Resources</b></font>
      <p>
<font face="Arial" size="2"><a href="../publications.htm">Publications</a></font>
      </p>
      <p><font face="Arial" size="2"><a href="../sound_picture_cd.htm">Sound
      recordings</a></font></p>
<p><font face="Arial" size="2"><a href="../links.htm">Links</a></font></p>
<p><font face="Arial" size="2"><a href="../Constant_directivity_louds.htm">Other
designs</a></font></p>
<p><font face="Arial" size="2"><a href="../my_setup.htm">My current setup</a></font></p>
<p><font face="Arial" size="2"><a href="../about_me.htm">About me</a></font></p>
<p><font face="Arial" size="2"><a href="../page_index.htm">Site map</a></font></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF">
      <p align="center"><a href="../index.htm"><b><font face="Arial" size="4" color="#008080">HOME</font></b></a></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>

<table border="0" width="100%" bgcolor="#FFFFFF" cellspacing="4" cellpadding="5">
  <tr>
    <td width="100%" background="../images/graphics/bg-notepaper1.gif"><font face="Arial"><b><font color="#FF0000" size="3" face="Arial"><i>------------------<br>
      </i></font><font color="#000000"><a href="../dpp/introduction.htm"><font size="3" face="Arial">Digital
      Photo<br>
      Processes</font></a></font></b></font>
    </td>
  </tr>
</table>

<p>&nbsp;</p>

<table border="0" width="100%" bgcolor="#FFFFFF" cellspacing="4" cellpadding="5">
  <tr>
    <td width="100%" background="../images/graphics/bg-notepaper1.gif"><font face="Arial"><b><font color="#FF0000">------------------</font><br>
      <a href="../Sea-Ranch/northern_california.htm">The<br>
      Sea Ranch</a></b></font>
    </td>
  </tr>
</table>

<p>&nbsp;</p>

<table border="0" width="100%" bgcolor="#FFFFFF" cellspacing="4" cellpadding="5">
  <tr>
    <td width="100%" background="../images/graphics/bg-notepaper1.gif"><font face="Arial"><b><font color="#FF0000">------------------</font><br>
      <a href="../Monika/MyDaughterTheJeweler.htm">My Daughter<br>
      the Jeweler</a></b></font>
    </td>
  </tr>
</table>

<h4>&nbsp;</h4>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF"><a href="../What_is_new_at_linkwitzlab.htm"><b><font face="Arial" color="#008080" size="4">What's
      new</font></b></a></td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF">
      <p align="center"><b><a href="../Store/windows.htm" target="_blank"><font face="Arial" size="4" color="#008080">LX
      - Store</font></a></b></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF">
      <p align="center"><a href="../Fitz/considerations.htm" target="_blank"><b><font face="Arial" color="#008080" size="3">Conversations<br>
      with Fitz</font></b></a></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>
<table border="3" width="100%" bgcolor="#FFFFFF" cellpadding="5" cellspacing="1" bordercolor="#008080">
  <tr>
    <td width="100%" bgcolor="#FFFFFF">
      <p align="center"><a href="http://oplug-support.org/" target="_blank"><b><font face="Arial" color="#008080" size="3">OPLUG<br>
      Forum</font></b></a></p>
    </td>
  </tr>
</table>
<p>&nbsp;</p>

<p>&nbsp;</p>

</td><td valign="top" width="24"></td><!--msnavigation--><td valign="top">

<p>&nbsp;</p>
<h1> <a name="Recording"> <font face="Arial" color="#FF0000"> Recording</font></a> <font face="Arial" color="#FF0000"> &amp; Rendering</font></h1>
<p><font face="Arial">--- <b><font color="#000000">Recording
&amp; Rendering 101</font></b>  --- <a href="acoustics-hearing.htm">Acoustics
vs. Hearing</a>
--- &nbsp;<a
href="EBU_evaluation_CD.htm">Subjective evaluation</a> ---&nbsp;<br>
--- <a href="../stereo&#32;reproduction.htm">Room
optimized stereo</a> --- <a href="../reproduction.htm">Sound reproduction</a> ---
<a href="Stereo-recording.htm">Recording
what we hear</a>  ---<br>
--- <a href="Stereo-recording-praxis.htm">Experimental results</a>
 --- <a href="record-play-map.htm">Theory</a>  --- <font color="#000000"> <a href="recording_angles.htm">SRA</a></font>
 ---&nbsp;<a href="../Sound_field/Field_control.htm">Sound field
control</a> --- Phantom sources ---
</font></p>
<p>&nbsp;</p>
<h1>&nbsp;</h1>
<h1><font face="Arial" color="#008080">Stereo Recording &amp; Rendering - 101</font></h1>
<p><font face="Arial" color="#008080"><b>Definition of processes:</b></font></p>
<p><font face="Arial"><b>1 - Recording<br>
</b>Microphones pick up sounds generated by performers of the art. Microphones
have 3D directional properties, with which they sample the sound field. The
output signals from n-microphones are recorded and stored in analog or digital
format on a storage medium. The recording engineer has set up or hung the
microphones to optimally achieve his objectives within the given constraints.</font></p>
<p><font face="Arial"><b>2 - Rendering<br>
</b>The recording engineer down-mixes the n-microphone signals to 2.0, 5.1 or
7.1 channels using an acoustically treated recording studio and his preferred
monitor loudspeakers. Other speakers may also be used to hear how the recording
translates. This process must be called 'rendering the art', because it is
unlikely that a person would have heard the same sound live. The performance,
the art, is rendered according to the desires of the recording engineer,
conductor and producer. The outcome of this process is misleadingly called 'The
Recording'. In addition to the musicians and performers of the art it carries
the signature of the people who made the specific 'recording'.</font></p>
<p><font face="Arial"><b>3 - Reproducing<br>
</b>When the recording is played back in the home a listener is unlikely to hear
a reproduction of what the mixing engineer heard in his studio with his
monitors. He hears a rendering of the recording, which is defined largely by the
on-axis response of his speakers and their illumination in 3D of his listening
room and the room's acoustics. The recording studio acoustics are quite dead so
that the direct sound from the speakers dominates what the recording engineer
hears and uses for his mixing decisions. A home listening environment is much
more live than a recording studio and it is difficult and costly to change it
into the acoustics of a purpose-built studio. Besides it would not be a pleasant
acoustic environment to live in other than for sound reproduction. Fortunately
loudspeakers can be built such that our hearing will focus on the direct sound
and withdraw attention from the room sound. Thus it becomes possible to hear
what the recording engineer heard and even more, because conventional monitor
loudspeakers have limitations.</font></p>
<p>&nbsp;</p>
<div align="center">
  <center>
  <table border="0" width="100%">
    <tr>
      <td width="8%"></td>
      <td width="58%">
<p><font face="Arial"><a href="AS_creation.htm#1.00">1.0&nbsp; </a>Binaural - Directly from
eardrum to eardrum<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="AS_creation.htm#1.10">1.1&nbsp; </a>Binaural
in practice<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="AS_creation.htm#1.20">1.2&nbsp; </a>Quasi-binaural
recording for loudspeaker playback<br>
<a href="AS_creation.htm#2.00">2.0&nbsp; </a>From mono to stereo by panning<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="AS_creation.htm#2.10">2.1&nbsp; </a>Recording
and rendering with paired microphones<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="AS_creation.htm#2.20">2.2&nbsp; </a>Rendering
below 1 kHz<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="AS_creation.htm#2.30">2.3&nbsp; </a>Spaced
microphones<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="AS_creation.htm#2.40">2.4&nbsp; </a>Blending
AB and XY recording techniques<br>
<a href="AS_creation.htm#3.00">3.0&nbsp; </a>Rendering in a reverberant environment<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="AS_creation.htm#3.10">3.1&nbsp; </a>Loudspeaker
placement<br>
<a href="AS_creation.htm#4.00">4.0&nbsp; </a>Summary<br>
<a href="AS_creation.htm#5.00">5.0&nbsp; </a>References</font></p>
      </td>
      <td width="34%"></td>
    </tr>
  </table>
  </center>
</div>
<p>&nbsp;</p>
<h3><a name="1.00"><font color="#008080" face="Arial">1.0</font></a><font color="#008080" face="Arial">&nbsp; Binaural - Directly from
eardrum to eardrum</font></h3>
<table border="0" width="100%" cellspacing="5" cellpadding="10" height="429">
  <tr>
    <td width="40%" valign="top" height="403"><font face="Arial">In its most accurate, but
      highly impractical form, a binaural recording captures the eardrum signals
      of a particular person at an acoustic event. The signals are then played
      back for the same person using headphones, which have been equalized so
      that the identical signal is reproduced at the eardrums as was present there during
      recording, Figure 1. The same small microphones (behind thin, flexible plastic tubes
      almost touching the eardrums) as used during recording, are also used to
      equalize the headphones for playback. It has been reported that on
      playback the aural scene is localized
      outside of the head, even when in frontal line of sight <b>[1]</b>. If the head
      is turned sideways during recording, then the aural scene turns sideways during playback.&nbsp;
      But if the head is turned during playback, then the eardrum signals do not
      change and the position of the aural scene moves with the head, which is unnatural. This tends to collapse the
      aural scene to a location inside the head.&nbsp;</font>
    </td>
    <td width="50%" valign="top" height="403"><font face="Arial">&nbsp;&nbsp;&nbsp; <img border="0" src="3-binaural.jpg" width="500" height="250"></font>
      <p><font face="Arial"><b>FIG. 1</b>&nbsp; Binaural recording and
      reproduction of the eardrum signal</font></p>
      <p><font face="Arial">Note that the frequency responses of head, pinna and
      ear canal of the listening individual are imbedded in the recording. Equalization of
      the headphones removes enclosed pinna and ear canal resonances in order to
      reproduce the recorded signal exactly at the ear drum, but only for that
      one individual.&nbsp; <a href="AS_creation.htm#Recording">Top</a></font></p>
    </td>
  </tr>
</table>
<h3><a name="1.10"><font face="Arial" color="#008080">1.1</font></a> <font face="Arial" color="#008080"> Binaural in practice</font></h3>
<div align="center">
  <center>
  <table border="0" width="100%" cellpadding="5">
    <tr>
      <td width="24%" valign="bottom"><font face="Arial"><br>
        <img border="0"
        src="artificial_head.jpg" width="197" height="250"></font>
      </td>
      <td width="76%" valign="bottom"><p><font face="Arial">In practice an
        artificial head is used, with outer ears of generic shape and texture.
        Neck, shoulders and upper body are included for scientific work'&nbsp;
        Figure 2.&nbsp; Microphones are usually mounted at the ear canal
        entrance. The microphone signal frequency response describes the
        Head-Related-Transfer-Function, HRTF, for blocked ear canals of this
        manniquin.</font></p>
        <p><font face="Arial">The microphone signals may be reproduced via
        over-the-ear, on-top-of-the-ear or in-the-ear headphones and thus be
        rendered differently depending upon the type and make of the phones.
        Localization of the aural scene is typically inside the head or very near the
        head. The aural scene stays locked to the head as the head is moved or turned.
        This is unnatural and the major flaw of binaural. It is completely
        overcome with a head tracking system. There is also a lack of tactile
        perception of vibration even when the sound volume is very high. But
        binaural can provide a very high degree of realism due to low non-linear
        distortion and being isolated from ambient sounds. You can have the
        sensation of someone whispering into your ears, which is impossible to
        achieve with stereo loudspeakers.&nbsp; <a href="AS_creation.htm#Recording">Top</a></font></p>
        <p><font face="Arial"><b>FIG. 2</b>&nbsp; <a
        href="http://www.gras.dk/00012/00330/" target="_blank">Artificial head</a>, opened to
        show microphone mounting fixture and outer ear</font></td>
    </tr>
  </table>
  </center>
</div>
&nbsp;
<p>&nbsp;</p>
<h3><a name="1.20"><font face="Arial" color="#008080">1.2</font></a> <font face="Arial" color="#008080"> Quasi-binaural recording for loudspeaker playback</font></h3>
<p><font face="Arial">It would seem natural that binaural recordings should work
well for stereo loudspeaker sound reproduction. But the frequency response above
about 3 kHz of the microphone pickup at the blocked ear canal is strongly
determined by the shape and detail of the outer ear and the direction of sound
incidence. This is the Interaural-Level-Difference, ILD frequency range of
directional hearing. When this signal is reproduced over loudspeakers the
response variations impart a coloration and misleading directional cues to the
signals arriving from +/-30<sup>0</sup> at the listener's ears. Stereo recording
microphones therefore have no pinna. The shape of the head and the distance
between the ears causes sounds to arrive at the ears at slightly different times
depending upon the direction of the sound source. Arrival times differ by less
than 700 </font><font face="Symbol">m</font><font face="Arial">s, which is used
to give the brain directional cues in the Interaural-Time-Difference, ITD
frequency range of hearing below 800 Hz. ITD and ILD are elements of the
Head-Related-Transfer-Function, HRTF.</font></p>
<div align="center">
  <center>
  <table border="0" width="100%" cellpadding="5">
    <tr>
      <td width="31%" valign="top"><font face="Arial"><img border="0"
        src="sphere_mic.jpg" width="250" height="250"></font>
        <p><font face="Arial"><b>FIG. 3</b>&nbsp; Microphone capsules placed&nbsp;<br>
 on
        the surface of a 19 cm sphere</font></td>
      <td width="69%" valign="top"><font face="Arial"><img border="0"
        src="head_mic.jpg" width="333" height="250"></font>
        <p><font face="Arial"><b>FIG. 4</b>&nbsp; Omni-directional microphone
        capsules&nbsp;<br>
 placed close to the ears, but not inside the pinna</font></td>
    </tr>
  </table>
  </center>
</div>
<p><font face="Arial">A sphere microphone preserves the spacing between the ears
for low frequency sound localization and provides blockage of sound between the
ears for the higher frequencies, Figure 3, <b>[2]</b>. I have used this microphone and a
similar setup for my own head, Figure 4, to make <a
href="../sound_picture_cd.htm">recordings</a> of events where I also then had a
direct memory of what I heard. This gave me material to evaluate my loudspeaker
designs.</font></p>
<p><font face="Arial">Sphere microphone are not optimal for rendering the
recorded aural scene over two loudspeakers. The spacing between the microphones
and the lack of low frequency directivity introduces misleading spatial cues in
the ITD range of hearing and affects the realistic creation of phantom sources
and aural scene. This will be shown below where loudspeaker stereo is explained.&nbsp;
&nbsp; <a href="AS_creation.htm#Recording">Top</a></font></p>
<h3>&nbsp;</h3>
<h3><a name="2.00"><font face="Arial" color="#008080">2.0</font></a><font face="Arial" color="#008080">&nbsp;
From mono to stereo by panning</font></h3>
<p><font face="Arial">Stereo over two loudspeakers works by creating a phantom
acoustic scene between the loudspeakers. In its simplest form a single monaural
signal is fed to both left and right loudspeakers. If the two loudspeaker levels
are identical and there is no phase difference between them, then a listener on
the center line between the loudspeakers will hear the monaural sound as coming
from the center though there is no sound coming from that direction. This is
basically a very unnatural event and so a slight movement to the left or right
will shift the phantom source to the nearer loudspeaker. If the monaural signal
is artificial, like pink noise, then there will also be a change in tonal color
at certain off-center locations due to interference of left and right
loudspeaker signals at the ears. This has been called &quot;the fundamental flaw
of 2-channel stereo&quot; and a reason for promoting a center channel in 5.1
surround <b>[3]</b>. But surround has its own phantom source issues, between L and C,
between C and R and more.<br>
While the off-center interference is audible with pink noise, it is not an issue
with signals that are known to the brain like music or voice and when there is a
reverberant sound field due to the listening room. The timbre of sound from a
center loudspeaker can be somewhat different from the timbre of the
corresponding center phantom source, because sound arrives from different angles
at&nbsp; the ears in the two cases. Thus their HRTF and the number of sound
streams is different, but the brain compensates effectively.</font></p>
<div align="center">
  <center>
  <table border="0" width="100%" cellpadding="5">
    <tr>
      <td width="48%" valign="top"><font face="Arial"><img border="0"
        src="panned_phantom250.jpg" width="513" height="250"></font>
        <p><font face="Arial"><b>Fig. 5</b>&nbsp;&nbsp; By reproducing a single
        channel signal over two loudspeakers a phantom source is perceived
        between the loudspeakers <b>[4]</b></font></td>
      <td width="52%" valign="top"><font face="Arial"><img border="0"
        src="mixing-board.png" width="338" height="250"></font>
        <p><font face="Arial"><b>Fig. 6</b>&nbsp; 32-channel mixing-board and
        recording monitors to create a phantom acoustic scene from up to 32
        individual signals</font></td>
    </tr>
  </table>
  </center>
</div>
<p>&nbsp;</p>
<div align="center">
  <center>
  <table border="0" width="100%" cellpadding="5">
    <tr>
      <td width="53%" valign="top"><font face="Arial">Primarily level panning is
        used for recording because it provides a more defined phantom source,
        Figure 5 and Figure 7. Today the majority of recordings are produced by
        down-mixing a multiplicity of monaural tracks of different instrument
        pick-ups into a 2-channel or n-channel format, Figure 6. Today, the
        large mixing board is implemented in digital form on a computer with a
        large screen display.</font>
        <p><font face="Arial">The mix-down often involves equalization, the
        addition of reverberation and compression in order to fit the taste of
        the recording engineer and market expectations as seen by the producer.</font></p>
        <p><font face="Arial">Panning distributes phantom sources along a line
        between the loudspeakers. The distance of the phantom scene from a
        listener is essentially given by the distance between listener and
        loudspeaker. If the loudspeakers are highly directional and the room is
        acoustically dead, then the image is sometimes closer than the
        loudspeakers, approaching headphone listening. Depth and height behind
        the loudspeaker line depends upon cues that the brain receives from
        reverberation and volume levels of sources in the recording. It is
        difficult to produce a spatially coherent mix from multiple tracks that
        is believable. The result is typically a collage of phantom sound
        clusters next to and on top of each other, or a wash of diffuse
        sound.&nbsp;</font></p>
        <p><font face="Arial">Since the majority of loudspeakers interact with
        the listening room unfavorably and they are also set up too close to the
        walls, few listeners notice the spatial distortion in the recording.
        They probably have never experienced the realism that 2-channel stereo
        is capable of when recording and reproduction are executed optimally.&nbsp;&nbsp;&nbsp;
        <a href="AS_creation.htm#Recording">Top</a></font></td>
      <td width="47%" valign="top"><font face="Arial"><img border="0"
        src="6-panning_law250.jpg" width="400" height="250"></font>
        <p><font face="Arial"><b>Fig. 7</b>&nbsp; Placement of the phantom
        source between the loudspeakers depends upon level and timing
        differences between the loudspeaker signals <b>[5]</b></font></td>
    </tr>
  </table>
  </center>
</div>
<h3>&nbsp;</h3>
<h3><a name="2.10"><font face="Arial" color="#008080">2.1</font></a> <font face="Arial" color="#008080"> Recording and rendering with paired microphones</font></h3>
<div align="center">
  <center>
  <table border="0" width="100%" cellpadding="5">
    <tr>
      <td width="33%" valign="top"><font face="Arial"><img border="0"
        src="polars2-s.png" width="350" height="338"></font>
        <p><font face="Arial"><b>Fig. 8</b>&nbsp; Polar responses of <b>Omni</b>-directional,
        <b>W</b>ide-cardioid, <b>C</b>ardioid, <b>S</b>uper-cardioid, <b>H</b>yper-cardioid
        and <b>B</b>i-directional microphones with identical outputs at 0<sup>0</sup>
        sound incidence angle. Output polarity is reversed with three of the
        microphone types for sound incidence from the rear.</font></td>
      <td width="33%" valign="top"><font face="Arial"><img border="0"
        src="polars-angled2-s.png" width="329" height="338"></font>
        <p><font face="Arial"><b>Fig. 9</b>&nbsp; Polar responses of two
        cardioid microphones at +/-55<sup>0</sup> angle to each other in the
        horizontal plane and mounted on top of each other for coincident sound
        arrival at the microphones. A signal at 25<sup>0</sup> incidence, for
        example, produces a larger output level from the right microphones than
        from the left microphone.</font></td>
      <td width="34%" valign="top"><font face="Arial">Microphones are built with
        a wide variety of directional characteristics. A few types are shown in
        Figure 8. The directional behavior is usually frequency dependent to
        some degree and more so with large diameter and large area microphones.
        An issue with directional microphones is decreased sensitivity to lower
        frequencies, high sensitivity to wind noise, pop and shock. Unlike
        omni-directional microphones, which are sealed sound pressure sensors,
        directional microphones result from a combination of omni- and
        bi-directional elements. The bi-directional element is sensitive to
        sound particle velocity and its direction.&nbsp;</font>
        <p><font face="Arial">A coincident pair of directional microphones
        pointing in different directions will have have outputs that are
        in-phase but differ in amplitude when sound is incident at angles other
        than 0<sup>0</sup> or 180<sup>0</sup>, Figure 9.</font></td>
    </tr>
  </table>
  </center>
</div>
<p>&nbsp;</p>
<div align="center">
  <center>
  <table border="0" width="100%" cellpadding="5">
    <tr>
      <td width="50%" valign="top"><font face="Arial"><img border="0"
        src="polars-linear2-s.png" width="534" height="300"></font></td>
      <td width="50%" valign="top"><font face="Arial"><b>Fig. 10</b>&nbsp; The
        polar diagram of Figure 9 has been redrawn with a linear axis for the
        angle of sound incidence and the ratio of right to left outputs in dB
        has been added. The ratio determines the position of a corresponding
        phantom source between the loudspeakers according to the panning law of
        Figure 7.</font>
        <p><font face="Arial">For example, at 25<sup>0</sup> incidence we see
        that R/L = 4 dB. Using this value and 0 ms time difference between the
        channels in Figure 7, we find that the phantom source should be about 15<sup>0</sup>
        to the right of center or 50% towards the right loudspeaker at 30<sup>0</sup>.
        The 10 dB level difference from a signal at 55<sup>0</sup> will produce
        a phantom source at about 25<sup>0</sup> or 83%. The 90<sup>0</sup> and
        135<sup>0</sup> signals map into the right loudspeaker. Any signal at
        180<sup>0</sup> will show up as a center phantom.</font></td>
    </tr>
  </table>
  </center>
</div>
<p><font face="Arial">Any pair of angled, coincident, directional microphones
will automatically pan the recorded acoustic scene onto the line between left
and right loudspeakers as a phantom scene. It will pan into left and right
loudspeakers as monaural signals those portions of the +/-180<sup>0</sup> view,
which do not translate into phantom sources, because the microphone output
levels differ too much. The monaural signals are problematic because they set
hard boundaries to the phantom scene, which usually is not in keeping with the
spread of the aural scene. It draws attention to the loudspeakers and their
location, rather than letting the loudspeakers disappear from perception with
eyes closed.</font></p>
<div align="center">
  <center>
  <table border="0" width="100%" cellpadding="5">
    <tr>
      <td width="50%" valign="bottom"><font face="Arial"><img border="0"
        src="front_mic-setup2-s.jpg" width="500" height="375"></font></td>
      <td width="50%" valign="bottom"><font face="Arial"><b>Fig. 11</b>&nbsp;
        Near-coincident pair of microphones. They are mounted at an angle to
        each other and to a stand with two shock mounts.</font></td>
    </tr>
  </table>
  </center>
</div>
<p><font face="Arial">Different types of directional microphones arranged as XY
coincident, as near coincident or spaced pairs will lead to a different
distribution of the recorded acoustic scene on a standard +/-30<sup>0</sup>
loudspeaker setup for reproduction, Figure 11.&nbsp; It is important to know the
&quot;Stereo Recording Angle&quot; of a particular pair of microphones, because
it determines which portion of the 360<sup>0</sup> acoustic scene to be recorded
will show up between the loudspeakers and with what linearity of distribution
between the +/-75% points symmetrical to the center location. This has been
calculated and catalogued with a JAVA applet following a panning law like in
Figure 7, <b>[6]</b>.&nbsp; Results for a pair of cardioid microphones are shown in Figure
12.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</font></p>
<p><img border="0" src="card55-s.png" width="323" height="223">&nbsp; <img
border="0" src="card75-s.png" width="323" height="223">&nbsp; <img border="0"
src="card55-17cm-s.png" width="323" height="223"></p>
<p><font face="Arial"><b>Fig. 12</b>&nbsp; Stereo recording angle for three
different arrangements of cardioid microphone pairs.</font></p>
<p><font face="Arial">The phantom positions for the +/-55<sup>0</sup> coincident
pair must have been derived from a different panning relationship than in Figure
7. At 25<sup>0</sup> incidence the phantom source is at 30% or 9<sup>0</sup> off
center whereas from Figure 10 and Figure 7 it would be at 50% and 15<sup>0</sup>.
It should be noted that panning relationships have been determined empirically.
Different investigators report different results, also depending upon source
material. Directional hearing is a brain process and subjective. Nevertheless
the graphs can show trends. Widening the angle to +/-75<sup>0</sup> places a
narrower +/-42<sup>0</sup> section of the acoustic scene between the 75% points,
whereas before it were +/-59<sup>0</sup>. Separating the microphones by 17 cm
leads to the well know ORTF arrangement. It further narrows the 75% rendered
angle to +/-34<sup>0</sup>. The graphs only cover the +/-90<sup>0</sup> frontal
plane, not +/-180<sup>0</sup> and elevation.&nbsp; It also cannot be deduced
from them how recorded and monaurally rendered left and right loudspeaker
signals might affect spatial perception. What exactly then are the aural
differences between the three arrangements in Figure 12?&nbsp;</font></p>
<p><font face="Arial">The SCHOEPS Mikrofone website provides sound samples of
recordings, which use the same recording angle, but where the types of
microphone pairs differ <b>[7]</b>.&nbsp; In general, only an experienced
recording engineer with adequate monitor loudspeakers might know how direct,
reflected and reverberant sounds from various directions combine in a particular
venue at the microphones and will be rendered over two loudspeakers. The monitor
loudspeakers used, their setup and environment influence the decisions made by
the recording engineer and limit the timbral, spatial and musical quality of the
end product, if they impose their own signature or are not fully trustworthy for
the task.&nbsp;&nbsp; <a href="AS_creation.htm#Recording">Top</a></font></p>
<p>&nbsp;</p>
<h3><a name="2.20"><font face="Arial" color="#008080">2.2</font></a><font face="Arial" color="#008080">&nbsp; Rendering below 1 kHz</font></h3>
<p><font face="Arial">How does level panning, the sound of the same signal but
at different levels from left and right loudspeakers, produce a phantom source
between the loudspeakers? I call it a magic trick, because there is no
sound-wave coming from the direction of the phantom source. The phantom source
is a construct of the brain and based upon the signals at the eardrums. Below 1
kHz, where the wavelengths of sounds become large compared to the size of the
human head, the ear signals differ very little in magnitude. But if the sound
arrives from directions other than the vertical plane of head symmetry, then the
ear signals contain a time difference. It is called interaural time difference
or ITD and is a very strong contributor to directional hearing [<b>8, 9</b>].&nbsp;
Interaural level differences, ILD predominate above above 3 kHz where the head
and outer ear dimensions become large compared to the wavelengths of
sounds.&nbsp;</font></p>
<div align="center">
  <center>
  <table border="0" width="104%" cellpadding="5">
    <tr>
      <td width="34%" valign="top"><font face="Arial"><img border="0"
        src="ITD-sphere.png" width="313" height="300"></font>
        <p><font face="Arial"><b>Fig. 13</b>&nbsp; Sphere model of a head and
        sound path length from a distant source to left and right ear points</font></td>
      <td width="36%" valign="top"><font face="Arial"><img border="0"
        src="ITD-alpha.png" width="426" height="300"></font>
        <p><font face="Arial"><b>Fig. 14</b>&nbsp; Interaural time difference as
        function of sound incidence angle </font><font face="Symbol">a,</font><font
        face="Arial"> where ITD = r/c (</font><font face="Symbol">a</font><font
        face="Arial"> + sin </font><font face="Symbol">a</font><font
        face="Arial">)</font></td>
      <td width="34%" valign="top"><font face="Arial">A sphere model of the head
        without sound diffraction allows for easy calculation of ITD versus
        sound incidence angle </font><font face="Symbol">a,</font><font
        face="Arial"> Figure 13.</font>
        <p><font face="Arial">The maximum value of ITD becomes 263 </font><font
        face="Symbol">m</font><font face="Arial">s for a stereo system with
        loudspeakers at +/-30<sup>0</sup>, Figure 14.</font></td>
    </tr>
  </table>
  </center>
</div>
<p><font face="Arial">Each stereo loudspeaker sends its output to both left and
right ears where they add as vectors, Figure 15. The phantom source direction,
distance, size and sound are derived from the summed sound streams l and r. The
frequency response for l and r shows that both ear signals have identical (!)
magnitude, Figure 16a. Their level is maximum when L and R loudspeakers have the
same output. The level decreases at both ears equally when one of the
loudspeakers becomes louder and the other decreases while keeping L+R = constant
<b>[10]</b>.&nbsp;&nbsp;&nbsp;</font></p>
<div align="center">
  <center>
  <table border="0" width="106%" cellpadding="5">
    <tr>
      <td width="37%" valign="top"><font face="Arial"><img border="0"
        src="ITD-phantom.png" width="316" height="300"></font>
        <p><font face="Arial"><b>Fig. 15</b>&nbsp; Loudspeaker signal summation
        at the ears, which leads to phantom source perception.</font></td>
      <td width="33%" valign="top"><font face="Arial"><img border="0"
        src="SLD-freq-resp.png" width="427" height="300"></font>
        <p><font face="Arial"><b>Fig. 16</b>&nbsp; Frequency response of the
        summed ear signals. SPL at each ear (a) and group delay (b) as function
        of source level difference in dB.&nbsp;</font></td>
      <td width="34%" valign="top"></td>
    </tr>
  </table>
  </center>
</div>
<p><font face="Arial">The ear signals differ in time of arrival, Figure
16b.&nbsp; ITD is directly related to SLD. Additional values have been
calculated for a 500 Hz signal and are plotted in Figure 17 as a function of
level differences between the loudspeakers. The ITD values are compared to those
in Figure 14 for a real source. The comparison yields the phantom source angle </font><font
face="Symbol">g</font><font face="Arial">, which is thereby known as a function
of SLD, <b>[10]</b>. Knowing the output signals and their ratios for a
coincident pair of cardioid microphones, Figure 10, we can now derive the
phantom source angle </font><font face="Symbol">g</font><font face="Arial"> for
a given source angle </font><font face="Symbol">a</font><font face="Arial"> and
the relative sound level of the phantom source, Figure 18.&nbsp;</font></p>
<div align="center">
  <center>
  <table border="0" width="100%" cellpadding="5">
    <tr>
      <td width="46%" valign="bottom"><img border="0" src="gamma-SLD.png"
        width="422" height="300">
        <p>&nbsp;</td>
      <td width="54%" valign="bottom">&nbsp;
        <p><font face="Arial"><b>Fig. 17</b>&nbsp; Interaural time difference
        and phantom source angle </font><font face="Symbol">g</font><font
        face="Arial"> as a function of level differences between two
        loudspeakers at +/-30<sup>0</sup>.</font></p>
        <p>&nbsp;</td>
    </tr>
  </table>
  </center>
</div>
<div align="center">
  <center>
  <table border="0" width="100%" cellpadding="5">
    <tr>
      <td width="46%" valign="top"><font face="Arial"><img border="0"
        src="cardioid110.jpg" width="422" height="389"></font></td>
      <td width="54%" valign="top"><font face="Arial"><b>Fig. 18</b>&nbsp;
        Stereo rendering of a real source at angle </font><font face="Symbol">a</font><font
        face="Arial"> to a phantom source at angle </font><font face="Symbol">g</font><font
        face="Arial"> when level panned by a pair of coincident microphones at
        110<sup>0</sup> subtended angle. Transform of angle (a) and level (b)
        for a constant amplitude real source signal.</font>
        <p><font face="Arial">The -7 dB monaural signal at </font><font
        face="Symbol">g</font><font face="Arial"> = 30<sup>0</sup> is the rms
        sum of source signals between 110<sup>0</sup> and 140<sup>0</sup>.
        Linear addition of the four underlying signals would yield a level of -1
        dB.</font></td>
    </tr>
  </table>
  </center>
</div>
<p><font face="Arial">If pure time panning is used, where left and right
loudspeaker signals have the same magnitude and only differ in time, then the
resulting ear signals have zero (!) time difference. The level at each ear
changes in comb filter fashion with frequency and at a different rate for each
ear depending upon the time difference. This produces a sense of spaciousness
and maybe even a sense of phantom direction, but it is an unnatural phenomenon
and peculiar to two loudspeaker stereo. Even near-coincident microphone
recordings, as with an ORTF or a sphere microphone setup, would suffer from it
to some extent in the ITD frequency range.</font></p>
<p><font face="Arial">In the ILD frequency range the listener's head shadows the
+/-30<sup>0</sup> loudspeaker signals slightly, which reduces cross-talk and
together with the outer ear shape allows for level differences between the ears.
Phantom source direction is primarily based on transients in this
range.&nbsp;&nbsp; <a href="AS_creation.htm#Recording">Top</a></font></p>
<p>&nbsp;</p>
<h3><a name="2.30"><font face="Arial" color="#008080">2.3</font></a><font face="Arial" color="#008080">&nbsp; Spaced
microphones</font></h3>
<p><font face="Arial">Spaced microphone recording techniques are prone to large
amounts of leakage between sound pickups. In the case of spaced omnis each
microphone sees the whole acoustic scene from a different location. Each
microphone output emphasizes different sound sources due to greater proximity to
one or the other, Figure 19. For example the cello is closer to microphone B
than to A and its pickup will be [20*log(d2/d1)] dB stronger than from A. This
ratio will also be modified by the frequency dependent directional radiation
properties of the cello <b>[11]</b>. Furthermore the path length difference
[d2-d1] causes the output from microphone A to be delayed by [2.9*(d2-d1)] ms/m.
The sound stream produced by the cello in the output of microphone B can
therefore differ significantly in magnitude and phase from that in microphone
A.&nbsp;</font></p>
<div align="center">
  <center>
  <table border="0" width="100%" cellpadding="5">
    <tr>
      <td width="50%" valign="top"><font face="Arial"><img border="0"
        src="spaced-omnis.jpg" width="406" height="400"></font>
        <p><font face="Arial"><b>Fig. 19</b>&nbsp; Two microphones with with
        separation s pick up different streams of sound from the same
        instruments.</font></td>
      <td width="50%" valign="top"><font face="Arial"><img border="0"
        src="spaced-omnis-render.jpg" width="533" height="400"></font>
        <p><font face="Arial"><b>Fig. 20</b>&nbsp; The summed streams of
        microphone A are reproduced by the left loudspeaker and those of B by
        the right loudspeaker. Each ear receives a different sum of loudspeaker
        signals. The aural scene between the loudspeakers is created in the
        brain of the listener from the two ear signals.&nbsp;</font></td>
    </tr>
  </table>
  </center>
</div>
<p><font face="Arial">The clarinet, which is at equal distance [d3=d4] from A
and B will produce microphone outputs that still may differ</font> <font
face="Arial">in magnitude due to the directionality of clarinet sound radiation.
The path lengths d5 and d6 do not differ much for the more distant drum,
especially when compared to a wavelength, which is 3.4 m at 100 Hz. But since
the drum is a dipolar radiator for many of its membrane vibration modes, it
matters how it is facing A versus B. The strength and character of the sound
pickup could vary depending upon the separation s between the microphones.</font>&nbsp;
<font face="Arial">The group of violins close to A will be distant in the
microphone output B and of a different blend compared to their pickup from A.</font></p>
<p><font face="Arial">The two microphone signals A and B are transmitted to left
and right loudspeakers. If we only turn on the left loudspeaker by itself, then
we immediately localize the source of the sound as being the left loudspeaker.
We are likely to hear that the sound is made up of sound streams from violins,
clarinet, drum and cello when we listen for a while. We may develop a sense of
how close those instruments were to the microphone and hear the reverberation of
the venue when the drum is struck. Similarly when we only listen to the right
loudspeaker we will hear the cello more clearly and distinct from the more
distant violins. The clarinet may sound just the same. But what happens when
both loudspeakers are turned on? Now we experience a phantom scene between
loudspeakers and with spaciousness added. Localization becomes diffuse and when
many more instruments are involved, tends to cluster around left and right
loudspeakers with somewhat of a hole in the middle. Reversing the polarity of
one of the loudspeakers will usually not change the aural scene. The problem is
for the brain to decipher the two sound streams [Ll+Rl] and [Rr+Lr] into
something meaningful <b>[12]</b>. Spatial hearing is a process that has evolved
in humans over eons of time but there is little brain patterning for these types
of sound streams. Still, very enjoyable recordings have been made with spaced
microphones for 2-channel stereo. Here the recording engineer must find the
location for the spaced pair that yields an aesthetically pleasing recording
that does justice to the music's composition and the audience's
expectations.&nbsp; Detailed spatial rendering is usually of low priority, also
because many playback systems lack that capability.&nbsp;&nbsp; <a
href="AS_creation.htm#Recording">Top</a></font></p>
<p>&nbsp;</p>
<h3><a name="2.40"><font face="Arial" color="#008080">2.4</font></a><font face="Arial" color="#008080">&nbsp; Blending AB and XY recording techniques</font></h3>
<p><font face="Arial">Instead of using A and B microphones in Figure 19 to
produce a 2-channel recording a single microphone could have been assigned to
the violins, the drum, clarinet and cello for a 4-channel recording. Unless
these microphones are placed very close to their individual instruments they
will pick up low levels of all the other instruments and the reverberant sound
in the venue. But if a microphone is very too close to an instrument it might
pick up a sound that is modified by the directional characteristics of the
instrument, that is unnatural and would normally not be heard by an audience <b>[11]</b>.
All this can be avoided by placing each musician in an isolation booth and with
headphones so he can hear everyone else to play in ensemble. Now we would have
four sound tracks that can be level panned between left and right monitor
loudspeakers to produce the 2-channel recording. Each track could even be panned
multiple times. Violins, drum, clarinet and cello tracks have become sound
objects that can be manipulated at will. The result is a collage of sound
clusters that hang like sheets of laundry on a clothes line between the
loudspeakers. Even when artificial reverberation is added to the mix the aural
scene remains spatially flat and unnatural.&nbsp;</font></p>
<div align="center">
  <center>
  <table border="0" width="100%" cellpadding="5">
    <tr>
      <td width="46%" valign="top"><img border="0" src="mic-setup.png"
        width="424" height="400">
        <p><font face="Arial"><b>Fig. 21</b>&nbsp; Microphone setups for
        preserving natural spatial relationships between sound sources and
        recording venue</font></td>
      <td width="54%" valign="top">
        <p ALIGN="JUSTIFY"><font face="Arial">It should be possible to use a
        single coincident XY microphone pair as the basis for rendering the
        spatial relationships between individual sound sources and their
        interaction with the reverberant sound field of the recording venue,
        Figure 21. The pair must be placed at some distance from the acoustic
        sources to minimize level differences between near and far instruments
        and to capture the width and height of the acoustic scene.</font></p>
        <p><font face="Arial">If necessary for clarity or audibility, individual
        sources or groups of instruments (a through k) are recorded as mono
        signals and then panned to the proper location in the phantom scene
        established by the XY pair. Electrical signal delay may be needed, if
        the required amplitude approaches the level of the XY pair output. When
        more than one microphone (f, g, h) is used to record a larger group of
        sound sources, then signal overlap and timing differences between the
        microphone outputs will lead to a loss of clarity when panned to left,
        center, right respectively. The microphones need to be close to the
        source to minimize leakage. The panned level of the microphones must be
        kept low not to override the precedence of the XY outputs. Two
        microphones (a, b) for a single source will add diffuseness, but only to
        the high frequency spectrum when placed close together. Widely spaced
        microphones (A, B) render a diffuse sound depending upon their distance
        from sources. They are useful for low frequency pickup when further away
        from the orchestra.&nbsp;&nbsp;&nbsp; <a href="AS_creation.htm#Recording">Top</a></font></td>
    </tr>
  </table>
  </center>
</div>
<h3>&nbsp;</h3>
<h3><a name="3.00"><font color="#008080" face="Arial">3.0</font></a><font color="#008080" face="Arial">&nbsp; Rendering in a reverberant environment</font></h3>
<p><font face="Arial">Listening to stereo usually takes place in an enclosed
space. It means that the loudspeaker signal is reflected by walls and objects in
the room not only once but again and again as it bounces around, Figure 22. The
signal loses energy with each reflection. Very quickly the sound level in the
room, away from the loudspeakers, becomes independent of listener location. That
level is established by the rate at which acoustic power is fed into the room
and the rate at which the reverberated sound is dissipated as heat by walls and
objects.&nbsp; A listener very close to the loudspeakers will hear primarily the
direct sound. At greater distance from the loudspeakers the reverberated and
diffuse sound in the room dominates. It is louder than the direct sound at that
location. The distance from the loudspeakers, at which direct and reverberant
sound levels are equal, is called the reverberation radius or critical distance <b>[13]</b>.</font></p>
<div align="center">
  <center>
  <table border="0" width="100%" cellpadding="5">
    <tr>
      <td width="50%" valign="top"><font face="Arial"><img border="0"
        src="reflect-reverb.png" width="593" height="300"></font></td>
      <td width="50%" valign="top"><font face="Arial"><b>Fig. 22</b>&nbsp; Wave
        tank display of a source S radiating a constant wavelength signal into a
        bounded surface.<br>
        (B) Reflection of the initial wave by surrounding walls. Reflection and
        diffraction by objects. The circular object is in a plane wave or
        free-field situation for a short time.<br>
        (C) Snapshot of the reverberating wave distribution at a later time. The
        circular object is immersed in a diffuse wave-field.</font></td>
    </tr>
  </table>
  </center>
</div>
<p><font face="Arial">At low frequencies, where the wavelength of sound is no
longer small compared to the dimensions of the room, the reverberant field takes
the form of standing waves or room modes. As a consequence, the difference in
sound level between two locations in the room can be very large at certain low
frequencies. Rendering problems can be minimized by installing acoustic
absorbers and/or minimizing the excitation of objectionable modes by woofer
placement and/or directivity.</font></p>
<div align="center">
  <center>
  <table border="0" width="100%" cellpadding="5">
    <tr>
      <td width="50%" valign="top"><font face="Arial"><img border="0"
        src="room-parameters.png" width="521" height="457"></font></td>
      <td width="50%" valign="top"><font face="Arial"><b>Fig. 23</b>&nbsp;
        Statistics of a room <b>[13]</b></font>
        <p>&nbsp;</p>
        <p><font face="Arial">For example, the room in Figure 23 has 21 possible
        modes below 100 Hz.&nbsp; The degree to which anyone of these is
        stimulated depends upon loudspeaker placement and radiation pattern. In
        addition, which of these are heard depends upon the listener's location
        in the room.&nbsp;</font></p>
        <p><font face="Arial">Mode frequencies are widely spaced at low
        frequencies. They become closer and eventually overlap as frequency
        increases. At the 120 Hz Schroeder frequency two mode frequencies fall
        within the 5.7 Hz resonance bandwidth of the modes.&nbsp;</font></p>
        <p><font face="Arial">The reverberation time T60 is an important measure
        of a room's acoustic properties. It describes how fast the reverberant
        sound in the room decays by 60 dB when the loudspeaker is turned off.
        Knowing T60 one can calculate the Schroeder frequency, which is the low
        frequency boundary of statistical room behavior. One can also calculate
        the critical distance.</font></p>
        <p><font face="Arial">&nbsp;</font></td>
    </tr>
  </table>
  </center>
</div>
<p><font face="Arial">A reverberation time of 384 ms means that 30% (41 m<sup>2</sup>
or 440 ft<sup>2</sup>) of the room surface area behaves acoustically like open
windows through which sound escapes. That is more than the floor area in size. A
shorter reverberation time requires even more absorption.&nbsp;</font></p>
<p><font face="Arial">The direct SPL from the loudspeaker, which decreases as
[1/distance], becomes equal to the reverberant sound level at 0.89 m, provided
that the loudspeaker radiates like a perfect omni. The critical radius becomes
1.55 m for an ideal dipole because of its directivity of 4.8
dB.&nbsp;&nbsp;&nbsp;</font></p>
<div align="center">
  <center>
  <table border="0" width="100%" cellpadding="5">
    <tr>
      <td width="33%" valign="top"><font face="Arial"><img border="0" src="../Watson/T60-V-S.png" width="473"
        height="396"></font>
        <p><font face="Arial"><b>Fig. 24</b>&nbsp; Reverberation time as
        function of room volume and surface area for different percentages of
        wall absorption.</font></td>
      <td width="33%" valign="top"><font face="Arial"><img border="0" src="../Watson/Rm-V.png" width="408" height="400"></font>
        <p><font face="Arial"><b>Fig. 25</b>&nbsp; Reverberation radius as
        function of room volume for different reverberation times.</font></td>
    </tr>
  </table>
  </center>
</div>
<p><font face="Arial">If we wanted T60 = 250 ms for the above room, then the
average wall absorption would have to increase to 54%, Figure 24. This will take
considerable effort to achieve and the room will no longer be experienced as a
normal living room. A reverberation time of 250 ms is required by EU
Broadcasting Standards for recording studios. The benefit of reduced
reverberation time is an increase in reverberation radius from 0.89 m to 1.30 m
for the monopole and from 1.55 m to 2.25 m for the dipole, Figure 25. Typical
studio monitors radiate omni-directional from low frequencies up to several hundredth
of Hz. They become increasingly forward directional as frequency increases, when
baffle and radiator sizes become first comparable and then large in size
relative to the wavelengths of radiated sound. Thus the reverberation radius and
the ratio of direct to reverberant sound will increase with frequency compared
to the monitor's lower frequency interaction with the studio room.<br>
A dipole loudspeaker with frequency independent directivity will readily achieve
the same direct-to-reverberant ratio in a more lively room as the typical
monitor loudspeaker in a recording studio.</font></p>
<p><font face="Arial">Statistical room parameters can be estimated from the
spreadsheet <a
href="../modes1.xls" target="_blank">modes1.xls</a>.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a
href="AS_creation.htm#Sensible"><br>
</a><a href="AS_creation.htm#Recording">Top</a></font></p>
<h3>&nbsp;</h3>
<h3><a name="3.10"><font color="#008080" face="Arial">3.1</font></a><font color="#008080" face="Arial">&nbsp; Loudspeaker
placement</font></h3>
<p><font face="Arial">The reflective and reverberant environment of a room
restricts the placement and radiation characteristics of the loudspeakers. The
equilateral triangle, formed by the loudspeakers and the listener in a stereo
system setup, must be placed symmetrical to the room boundaries or large objects
in the room, Figure 26. This ensures symmetry of the reflections relative to the
center axis and a sharply defined center phantom image for monaural loudspeaker
signals or center panned sounds. Each loudspeaker also must be placed at some
distance from front and side walls so that reflections reach the ears later than
the direct loudspeaker sounds. In that case the brain can filter out the direct
sound streams more readily from those due to reflection and reverberation. A
minimum time gap of 6 ms between direct and reflected sounds is needed, which
translates to a minimum distance of 1 m from the walls.&nbsp;</font></p>
<table border="0" width="100%" cellpadding="5">
  <tr>
    <td width="58%" valign="top"><font face="Arial"><img border="0"
      src="room-reflections.png" width="500" height="329"></font>
      <p><font face="Arial"><b>Fig. 26</b>&nbsp; Triangular loudspeaker and
      listener setup with symmetry relative to the walls and at some distance
      from them. The minimum distance is 1 m.<br>
      The left loudspeaker will generate spectrally incoherent sound streams at
      the observer's ears.</font></td>
    <td width="42%" valign="top"><font face="Arial"><img border="0"
      src="room-radius.png" width="328" height="329"></font>
      <p><font face="Arial"><b>Fig. 27</b>&nbsp; SPL in a room as function of
      distance from the loudspeaker. The listening distance should be less than
      twice the reverberation radius for D/R less than -6 dB.</font></td>
  </tr>
</table>
<p><font face="Arial">Furthermore, reflected sounds should be spectrally
coherent with the direct sound to a high degree for unambiguous perceptual
processing. Direct and reflected sounds then generate a reverberant sound field
that is spectrally coherent with the direct sound at the listener's ears <b>[14,
15, 16]</b>. Under those conditions a listener can withdraw attention from the
room and focus on the aural scene in front of him. Room and loudspeakers
disappear.&nbsp;</font></p>
<p><font face="Arial">Coherence of the room sound requires a frequency
independent polar response of the loudspeaker. It implies a constant directivity
loudspeaker such as a monopole, dipole or cardioid. Experience has shown that
the optimum listening distance should be less than twice the radiation radius so
that the direct sound is less than 6 dB below the reverberant sound level in the
room. In the example of&nbsp; Figure 23 that should be less than 1.8 m (6 ft)
for the monopole or 3.1 m (10 ft) for the dipole source. The maximum recommended
loudspeaker spacing would become 6 ft for the monopole or 10 ft for the dipole.
The dipole reaches deeper into the room because it interacts less with
it.&nbsp;&nbsp; <a href="AS_creation.htm#Recording">Top</a></font></p>
<p>&nbsp;</p>
<h3><a name="4.00"><font color="#008080" face="Arial">4.0</font></a><font color="#008080" face="Arial">&nbsp; Summary</font></h3>
<p><font face="Arial">The type and performance of loudspeakers used, their
setup, the listening distance and the room's acoustic properties determine the
quality of the rendered aural scene at the consumer's end of the acoustical
chain. The aural scene is ultimately limited by the recording.&nbsp;</font></p>
<p><font face="Arial">The type and configuration of microphones used, their
setup, the venue, the monitor loudspeakers for the mix, their setup, the
listening distance, the studio's acoustic properties and the mix determine the
quality of the recording at the producer's end of the acoustical chain between
performer and consumer.</font></p>
<p><font face="Arial">Monitor and consumer loudspeakers must exhibit close to
constant directivity at all frequencies in order to obtain optimal results for
recording and rendering.<br>
<a href="AS_creation.htm#Recording">Top</a></font></p>
<p>&nbsp;</p>
<h3><a name="5.00"><font color="#008080" face="Arial">5.0&nbsp;</font></a> <font color="#008080" face="Arial"> References</font></h3>
<p><font face="Arial">[1a] David Griesinger, <b> Frequency Response Adaptation in
Binaural Hearing</b>, 126th AES Convention, Munich 2009, Preprint 7768, <a
href="http://www.davidgriesinger.com" target="_blank">www.davidgriesinger.com</a></font></p>
<p><font face="Arial">[1b] David Griesinger, <b>Binaural Hearing, Ear Canals,
and Headphone Equalization</b>, <a
href="Binaural_hearing_and_headphones&#32;(1).ppt" target="_blank">PowerPoint
presentation</a></font></p>
<p><font face="Arial">[2] Joerg Wuttke, <b> Zwei Jahre Kugelflaechenmikrofon</b>, <a
href="Mikrofonbuch_Kap5.pdf" target="_blank">Mikrofonbuch_Kap5.pdf</a>, 1992, <a
href="http://www.schoeps.de/en/information" target="_blank">http://www.schoeps.de/en/information</a></font></p>
<p><font face="Arial">[3] Floyd E. Toole, <b> Sound Reproduction</b>, Focal Press, 2008</font></p>
<p><font face="Arial">[4] Peter Damaske, <b> Acoustics and Hearing</b>, Springer, 2008</font></p>
<p><font face="Arial">[5] Francis Rumsey, <b> Spatial Audio</b>, Focal Press, 2005</font></p>
<p><font face="Arial">[6] Helmut Wittek, <b>Image Assistant</b>, JAVA
applet for determining the &quot;Stereo Recording Angle&quot;, <a
href="http://www.hauptmikrofon.de" target="_blank">www.hauptmikrofon.de</a></font></p>
<p><font face="Arial">[7] SHOEPS Mikrofone, <b>Showroom</b>, <a
href="http://www.schoeps.de/en/applications/showroom" target="_blank">www.schoeps.de/en/applications/showroom</a></font></p>
<p><font face="Arial">[8] Jens Blauert, <b> Spatial Hearing</b>, The MIT Press, 1997</font></p>
<p><font face="Arial">[9] Eric Benjamin, <b>An experimental Verification of
Localization in Two-Channel Stereo</b>, 121st AES Convention, San Francisco
2006, Preprint 6968</font></p>
<p><font face="Arial">[10] Siegfried Linkwitz, <b>A Model for Rendering Stereo
Signals in the ITD-Range of Hearing</b>, 133rd AES Convention, San Francisco
2012, Preprint 8713,&nbsp; <a href="../publications.htm#34">Abstract</a>,&nbsp; <a
    href="http://www.linkwitzlab.com/Recording/Recording/ITD-Stereo-rendering2.pdf" target="_blank">Presentation
    slides</a></font></p>
<p><font face="Arial">[11] Juergen Meyer, <b>Acoustics and the Performance of
Music</b>, Springer, 2009</font></p>
<p><font face="Arial">[12] Albert S. Bregman, <b>Auditory Scene Analysis</b> -
The Perceptual Organization of Sound, The MIT Press, 1999</font></p>
<p ALIGN="LEFT"><font face="Arial">[13] Heinrich Kuttruff, <b>Room Acoustics</b>,
John Wiley &amp; Sons, 1973</font></p>
<p><font face="Arial">[14] Siegfried Linkwitz, <b>Room
Reflections Misunderstood?</b>, 123rd
AES Convention, New York, October 2007,
Preprint 7162, <a href="../AES123-final2.pdf" target="_blank">Manuscript</a>,</font></p>
<p ALIGN="LEFT"><font
face="Arial">[15]&nbsp; Brad Rakert, William M. Hartmann, &quot;<a
href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3003727/pdf/JASMAN-000128-003052_1.pdf"
target="_blank"><b>Localization of
sound in rooms</b>.</a> V. Binaural coherence and human sensitivity to interaural
time differences in noise&quot;, J. Acoust. Soc. Am., Vol. 128, No. 5, November
2010</font></p>
<p><font face="Arial">[16] William M. Hartmann, <b>Signals, Sound, and Sensation</b>,
Springer, 2005</font></p>
<p><font face="Arial">SL - 21 August 2012</font></p>
<p>&nbsp;</p>
<p><font face="Arial">See also:&nbsp;<a href="../Sound_field/Field_control.htm"><b><br>
<br>
Sound Field Control for Rendering Stereo</b></a></font></p>
<p><font face="Arial"><a href="../links.htm#Sound Recording">Links</a> - <b>Introduction
to Sound recording</b></font></p>
<p><font face="Arial"><b>Recording &amp; Rendering - <a name="101"> 101</a></b>&nbsp; can be
downloaded as <a href="Recording-Rendering-101.pdf">PDF</a></font></p>
<p>&nbsp;</p>
<p><font face="Arial"><a href="AS_creation.htm#Recording">Top</a></font></p>
<p>&nbsp;</p>
<p align="center">===========================================
        <p>&nbsp;
<p>&nbsp;</p>
<!--msnavigation--></td></tr><!--msnavigation--></table><!--msnavigation--><table border="0" cellpadding="0" cellspacing="0" width="100%"><tr><td>

<p>&nbsp;</p>
<table border="0" width="90%" cellpadding="10">
  <tr>
    <td width="10%" align="center"><a href="../IJAETv2n2a2-Linkwitz-1.pdf" target="_blank"><img border="0" src="../images/photos/SL-2013.jpg" width="150" height="200"></a></td>
    <td width="50%">
      <b><span style="letter-spacing: 1pt"><font color="#808080" face="Arial" size="5">What you hear is not the air pressure
      variation in itself&nbsp;<br>
      but what has drawn your attention<br>
 in the streams of superimposed air
      pressure variations&nbsp;<br>
 at your eardrums</font></span></b>
      <p><b><font
      face="Arial" size="4" color="#008080"><span style="letter-spacing: 1pt">An
      acoustic event has dimensions of Time, Tone, Loudness and Space<br>
      Have they been recorded and rendered sensibly?</span></font></b></p>
    </td>
  </tr>
  <tr>
    <td width="10%" colspan="2" align="center">
      <p><b><font face="Arial" color="#ff0000" size="5">___________________________________________________________<br>
      </font></b><font face="Arial" color="#000000" size="1">Last revised: 08/02/2018
      &nbsp; -&nbsp;  1999-2017 LINKWITZ LAB, All Rights Reserved</font>
      <p>&nbsp;</td>
  </tr>
</table>

</td></tr><!--msnavigation--></table><!-- WiredMinds eMetrics tracking with Enterprise Edition V5.4 START -->
<script type='text/javascript' src='https://count.carrierzone.com/app/count_server/count.js'></script>
<script type='text/javascript'><!--
wm_custnum='98f60a12c56b8f6c';
wm_page_name='AS_creation.htm';
wm_group_name='/services/webpages/l/i/linkwitzlab.com/public/Recording';
wm_campaign_key='campaign_id';
wm_track_alt='';
wiredminds.count();
// -->
</script>
<!-- WiredMinds eMetrics tracking with Enterprise Edition V5.4 END -->
</body>

</html>
